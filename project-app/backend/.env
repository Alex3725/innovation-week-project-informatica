# URL del servizio Ollama in esecuzione in locale
OLLAMA_BASE_URL=http://localhost:11434

# Modello da utilizzare per l'analisi. Assicurati di averlo scaricato con "ollama pull llama3"
OLLAMA_MODEL=llama3.1:8b
